{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ММО_РК-2","provenance":[{"file_id":"https://github.com/yomyaykya/yomyay/blob/master/MMO_PK2.ipynb","timestamp":1623836268211}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"I9_-b2Ui0Tku"},"source":["Рубежный контроль №2 по курсу \"Методы машинного обучения\"\n","\n","Студентка ИУ5И-22М Ван Пэй\n","\n","Методы обработки текстов. Решение задачи классификации текстов.\n","\n","Вариант: RandomForestClassifier ; Complement Naive Bayes (CNB)"]},{"cell_type":"code","metadata":{"id":"1S44zuii0egN"},"source":["import numpy as np\n","import pandas as pd\n","from typing import Dict, Tuple\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","from sklearn.metrics import accuracy_score, balanced_accuracy_score\n","from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import cross_val_score\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score \n","from sklearn.metrics import roc_curve, roc_auc_score\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.linear_model import LogisticRegression\n","import seaborn as sns\n","from collections import Counter\n","from sklearn.datasets import fetch_20newsgroups\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline \n","sns.set(style=\"ticks\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-S7-ccev08BX","executionInfo":{"status":"ok","timestamp":1623836358419,"user_tz":-180,"elapsed":10743,"user":{"displayName":"Pei Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxGhGrcYA-7pKshoIf8PHfdiebSYUuAiZXSuwt=s64","userId":"09690614275584117489"}},"outputId":"0e9c1a31-535a-45ef-f72b-37b8402645b5"},"source":["categories = [\"comp.os.ms-windows.misc\", \"sci.crypt\", \"talk.religion.misc\", \"rec.autos\"]\n","newsgroups = fetch_20newsgroups(subset='train', categories=categories)\n","data = newsgroups['data']"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading 20news dataset. This may take a few minutes.\n","Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"D2LV91E_MRX6"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NFPjpjur1AeG"},"source":["def accuracy_score_for_classes(\n","    y_true: np.ndarray, \n","    y_pred: np.ndarray) -> Dict[int, float]:\n","    \"\"\"\n","    Вычисление метрики accuracy для каждого класса\n","    y_true - истинные значения классов\n","    y_pred - предсказанные значения классов\n","    Возвращает словарь: ключ - метка класса, \n","    значение - Accuracy для данного класса\n","    \"\"\"\n","    # Для удобства фильтрации сформируем Pandas DataFrame \n","    d = {'t': y_true, 'p': y_pred}\n","    df = pd.DataFrame(data=d)\n","    # Метки классов\n","    classes = np.unique(y_true)\n","    # Результирующий словарь\n","    res = dict()\n","    # Перебор меток классов\n","    for c in classes:\n","        # отфильтруем данные, которые соответствуют \n","        # текущей метке класса в истинных значениях\n","        temp_data_flt = df[df['t']==c]\n","        # расчет accuracy для заданной метки класса\n","        temp_acc = accuracy_score(\n","            temp_data_flt['t'].values, \n","            temp_data_flt['p'].values)\n","        # сохранение результата в словарь\n","        res[c] = temp_acc\n","    return res\n","\n","def print_accuracy_score_for_classes(\n","    y_true: np.ndarray, \n","    y_pred: np.ndarray):\n","    \"\"\"\n","    Вывод метрики accuracy для каждого класса\n","    \"\"\"\n","    accs = accuracy_score_for_classes(y_true, y_pred)\n","    if len(accs)>0:\n","        print('Метка \\t Accuracy')\n","    for i in accs:\n","        print('{} \\t {}'.format(i, accs[i]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iNXCbrL41Dg1"},"source":["CountVectorizer"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iLEf7-UI1H_v","executionInfo":{"status":"ok","timestamp":1623836359055,"user_tz":-180,"elapsed":642,"user":{"displayName":"Pei Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxGhGrcYA-7pKshoIf8PHfdiebSYUuAiZXSuwt=s64","userId":"09690614275584117489"}},"outputId":"ec132120-71c6-4811-93ee-515068e64fbb"},"source":["vocabVect = CountVectorizer()\n","vocabVect.fit(data)\n","corpusVocab = vocabVect.vocabulary_\n","print('Количество сформированных признаков - {}'.format(len(corpusVocab)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Количество сформированных признаков - 63878\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3UHwRhAI1Mam","executionInfo":{"status":"ok","timestamp":1623836359429,"user_tz":-180,"elapsed":382,"user":{"displayName":"Pei Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxGhGrcYA-7pKshoIf8PHfdiebSYUuAiZXSuwt=s64","userId":"09690614275584117489"}},"outputId":"e6171644-06da-455d-debe-edefa06f4542"},"source":["for i in list(corpusVocab)[1:10]:\n","    print('{}={}'.format(i, corpusVocab[i]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["pp=46599\n","cbnewsl=19077\n","cb=19041\n","att=15577\n","com=20266\n","peter=45744\n","peng=45600\n","subject=54145\n","1990=2697\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T0H_AXu_1UUG","executionInfo":{"status":"ok","timestamp":1623836360026,"user_tz":-180,"elapsed":604,"user":{"displayName":"Pei Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxGhGrcYA-7pKshoIf8PHfdiebSYUuAiZXSuwt=s64","userId":"09690614275584117489"}},"outputId":"eb4ecfe9-ad78-42a6-d72f-07dbc8676c1e"},"source":["test_features = vocabVect.transform(data)\n","test_features"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<2157x63878 sparse matrix of type '<class 'numpy.int64'>'\n","\twith 381088 stored elements in Compressed Sparse Row format>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mMbdEl6f1Yvm","executionInfo":{"status":"ok","timestamp":1623836360743,"user_tz":-180,"elapsed":721,"user":{"displayName":"Pei Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxGhGrcYA-7pKshoIf8PHfdiebSYUuAiZXSuwt=s64","userId":"09690614275584117489"}},"outputId":"d68c4d58-e92d-4cd2-a9ac-2b3c2c8b9e37"},"source":["# Размер нулевой строки\n","len(test_features.todense()[0].getA1())"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["63878"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uw0PLf5n1cyF","executionInfo":{"status":"ok","timestamp":1623836360744,"user_tz":-180,"elapsed":14,"user":{"displayName":"Pei Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxGhGrcYA-7pKshoIf8PHfdiebSYUuAiZXSuwt=s64","userId":"09690614275584117489"}},"outputId":"f3c721c2-9cd5-43f8-9695-2b5d94dbdb11"},"source":["vocabVect.get_feature_names()[100:120]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['00101100',\n"," '00101100b',\n"," '00101101',\n"," '00101101b',\n"," '00101110',\n"," '00101110b',\n"," '00101111',\n"," '00101111b',\n"," '0011',\n"," '00110000',\n"," '00110000b',\n"," '00110001',\n"," '00110001b',\n"," '00110010',\n"," '00110010b',\n"," '00110011',\n"," '00110011b',\n"," '00110100',\n"," '00110100b',\n"," '00110101']"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"KZ4FqLkS1i5G"},"source":["def VectorizeAndClassify(vectorizers_list, classifiers_list):\n","    for v in vectorizers_list:\n","        for c in classifiers_list:\n","            pipeline1 = Pipeline([(\"vectorizer\", v), (\"classifier\", c)])\n","            score = cross_val_score(pipeline1, newsgroups['data'], newsgroups['target'], scoring='accuracy', cv=3).mean()\n","            print('Векторизация - {}'.format(v))\n","            print('Модель для классификации - {}'.format(c))\n","            print('Accuracy = {}'.format(score))\n","            print('===========================')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JizVfzAn1kfv","executionInfo":{"status":"ok","timestamp":1623836435439,"user_tz":-180,"elapsed":74703,"user":{"displayName":"Pei Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxGhGrcYA-7pKshoIf8PHfdiebSYUuAiZXSuwt=s64","userId":"09690614275584117489"}},"outputId":"8c157bcd-369f-40fc-862d-b4c5b54b195f"},"source":["vectorizers_list = [CountVectorizer(vocabulary = corpusVocab), TfidfVectorizer(vocabulary = corpusVocab)]\n","classifiers_list = [LogisticRegression(), MultinomialNB()]\n","VectorizeAndClassify(vectorizers_list, classifiers_list)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"},{"output_type":"stream","text":["Векторизация - CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n","                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n","                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n","                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n","                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n","                tokenizer=None,\n","                vocabulary={'00': 0, '000': 1, '00000000': 2, '00000000b...\n","                            '00000001': 4, '00000001b': 5, '00000010': 6,\n","                            '00000010b': 7, '00000011': 8, '00000011b': 9,\n","                            '00000100': 10, '00000100b': 11, '00000101': 12,\n","                            '00000101b': 13, '00000110': 14, '00000110b': 15,\n","                            '00000111': 16, '00000111b': 17, '00001000': 18,\n","                            '00001000b': 19, '00001001': 20, '00001001b': 21,\n","                            '00001010': 22, '00001010b': 23, '00001011': 24,\n","                            '00001011b': 25, '00001100': 26, '00001100b': 27,\n","                            '00001101': 28, '00001101b': 29, ...})\n","Модель для классификации - LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n","                   multi_class='auto', n_jobs=None, penalty='l2',\n","                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n","                   warm_start=False)\n","Accuracy = 0.956884561891516\n","===========================\n","Векторизация - CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n","                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n","                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n","                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n","                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n","                tokenizer=None,\n","                vocabulary={'00': 0, '000': 1, '00000000': 2, '00000000b...\n","                            '00000001': 4, '00000001b': 5, '00000010': 6,\n","                            '00000010b': 7, '00000011': 8, '00000011b': 9,\n","                            '00000100': 10, '00000100b': 11, '00000101': 12,\n","                            '00000101b': 13, '00000110': 14, '00000110b': 15,\n","                            '00000111': 16, '00000111b': 17, '00001000': 18,\n","                            '00001000b': 19, '00001001': 20, '00001001b': 21,\n","                            '00001010': 22, '00001010b': 23, '00001011': 24,\n","                            '00001011b': 25, '00001100': 26, '00001100b': 27,\n","                            '00001101': 28, '00001101b': 29, ...})\n","Модель для классификации - MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n","Accuracy = 0.7997218358831711\n","===========================\n","Векторизация - TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n","                dtype=<class 'numpy.float64'>, encoding='utf-8',\n","                input='content', lowercase=True, max_df=1.0, max_features=None,\n","                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n","                smooth_idf=True, stop_words=None, strip_accents=None,\n","                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n","                tokenizer=None, use...\n","                            '00000001': 4, '00000001b': 5, '00000010': 6,\n","                            '00000010b': 7, '00000011': 8, '00000011b': 9,\n","                            '00000100': 10, '00000100b': 11, '00000101': 12,\n","                            '00000101b': 13, '00000110': 14, '00000110b': 15,\n","                            '00000111': 16, '00000111b': 17, '00001000': 18,\n","                            '00001000b': 19, '00001001': 20, '00001001b': 21,\n","                            '00001010': 22, '00001010b': 23, '00001011': 24,\n","                            '00001011b': 25, '00001100': 26, '00001100b': 27,\n","                            '00001101': 28, '00001101b': 29, ...})\n","Модель для классификации - LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n","                   multi_class='auto', n_jobs=None, penalty='l2',\n","                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n","                   warm_start=False)\n","Accuracy = 0.9564209550301345\n","===========================\n","Векторизация - TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n","                dtype=<class 'numpy.float64'>, encoding='utf-8',\n","                input='content', lowercase=True, max_df=1.0, max_features=None,\n","                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n","                smooth_idf=True, stop_words=None, strip_accents=None,\n","                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n","                tokenizer=None, use...\n","                            '00000001': 4, '00000001b': 5, '00000010': 6,\n","                            '00000010b': 7, '00000011': 8, '00000011b': 9,\n","                            '00000100': 10, '00000100b': 11, '00000101': 12,\n","                            '00000101b': 13, '00000110': 14, '00000110b': 15,\n","                            '00000111': 16, '00000111b': 17, '00001000': 18,\n","                            '00001000b': 19, '00001001': 20, '00001001b': 21,\n","                            '00001010': 22, '00001010b': 23, '00001011': 24,\n","                            '00001011b': 25, '00001100': 26, '00001100b': 27,\n","                            '00001101': 28, '00001101b': 29, ...})\n","Модель для классификации - MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n","Accuracy = 0.879925822902179\n","===========================\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pqPkZPEI2gAv"},"source":["\n","**точность показал TfidfVectorizer и LogisticRegression (96%)**"]}]}